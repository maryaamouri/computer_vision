import mediapipe as mpimport cv2import timeimport numpycap = cv2.VideoCapture('people/2.mp4')#cap = cv2.VideoCapture(0)p_time = 0faceDetection= mp.solutions.face_detection.FaceDetection()mpDraw = mp.solutions.drawing_utilswhile True:    success, img = cap.read()    img = cv2.resize(img, (1080, 720))    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    results = faceDetection.process((imgRGB))    if results.detections:        for id, detection in enumerate(results.detections):            #mpDraw.draw_detection(img,detection)            bboxC = detection.location_data.relative_bounding_box            ih, iw, ic = img.shape            bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \                   int(bboxC.width * iw), int(bboxC.height * ih)            cv2.rectangle(img, bbox, (255, 0, 255), 2)            cv2.putText(img,  f'{int(detection.score[0] * 100)}%',                        (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN,                        2, (255, 0, 255), 2)    c_time = time.time()    fps = 1 / (c_time - p_time)    cv2.putText(img, f'FPS:{int(fps)}', (20, 70), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 0), 2)    p_time = c_time    cv2.imshow('face-detection', img)    cv2.waitKey(1)