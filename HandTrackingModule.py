import timeimport cv2import mediapipe as mpclass handDetector():    def __init__ (self, mode=False, maxHands =2, detectionCon=0.5,trackCon=0.5):        self.mode = mode        self.maxHands = maxHands        self.detectionCon = detectionCon        self.trackCon = trackCon        # define model        self.mpHand = mp.solutions.hands        self.hands = self.mpHand.Hands()        self.mpDraw = mp.solutions.drawing_utils    def findHands(self, img, draw= True):        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        self.results = self.hands.process(imgRGB)        if self.results.multi_hand_landmarks:            for handlms in self.results.multi_hand_landmarks:                if draw:                    self.mpDraw.draw_landmarks(img, handlms, self.mpHand.HAND_CONNECTIONS)        return img    def findPosition(self, img, handNo=0, draw= True):        lmlist =[]        if self.results.multi_hand_landmarks:            my_hand =self.results.multi_hand_landmarks[handNo]            for id,lm in enumerate(my_hand.landmark):                h, w, c = img.shape                cx, cy =int(lm.x*w), int(lm.y*h)                lmlist.append([id, cx,cy])                if draw:                    cv2.circle(img, (cx,cy),5, (50,5,200), cv2.FILLED)        return lmlistdef main():    pTime = 0    cTime = 0    cap = cv2.VideoCapture(0)    detector= handDetector()    while True:        succ, img = cap.read()        img= detector.findHands(img)        lmlist= detector.findPosition(img)        if len(lmlist)!=0:            print(lmlist[4])        # frame rate        cTime = time.time()        fps = 1 / (cTime - pTime)        pTime = cTime        # put text=> image, text, position, font family, scale, color, thickness        cv2.putText(img, str(int(fps)), (10, 90), cv2.FONT_HERSHEY_PLAIN, 3, (255, 0, 255), 3)        cv2.imshow('output ', img)        cv2.waitKey(1)if __name__ == "__main__":    main()